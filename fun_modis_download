modis_download = function(h=h, v=v, start=start, end=end, odir=odir, ds=c("MOD09GQ","MYD09GQ"), version=version) {
  
  #---------------------------------------------------------------------------------------------------------------#
  #---------------------------------------------------------------------------------------------------------------#
  #Description
  #---------------------------------------------------------------------------------------------------------------#
  #---------------------------------------------------------------------------------------------------------------#
  
  #function to download modis data for a given list of datasets.
  
  #components:
  #h = acquisition row (numeric)
  #v = aquisition path (numeric)
  #start = string of starting date (expressed in "yyyy-mm-dd")
  #end = string of ending date (expressed in "yyyy-mm-dd")
  #odir = output directory (string)
  #ds = string of target dataset(s)
  #version = numeric variable specifying the product version.
  
  #NOTE: requires R 3.2 or higher (download method "libcurl" not available in previous versions
  
  #---------------------------------------------------------------------------------------------------------------#
  #1. specify data server / check output directory
  #---------------------------------------------------------------------------------------------------------------#
  
  version = as.character(version)
  server = paste("ftp://ladsftp.nascom.nasa.gov/allData/", version, "/", sep="")
  if(substr(odir,nchar(odir),nchar(odir)) != "/") {odir = paste(odir, "/", sep="")}
  
  #---------------------------------------------------------------------------------------------------------------#
  #2. define target path/row
  #---------------------------------------------------------------------------------------------------------------#
  
  if(h < 10) {h = paste('0', as.character(h), sep="")} else {h = as.character(h)}
  if(v < 10) {v = paste('0', as.character(v), sep="")} else {v = as.character(v)} 
  
  #---------------------------------------------------------------------------------------------------------------#
  #3. call required packages
  #---------------------------------------------------------------------------------------------------------------#
  
  #check if package is isntalled
  pkgTest <- function(x){
    if (!require(x,character.only = TRUE)){
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
  }
  
  pkgTest("RCurl")
  library("RCurl")
  
  #setInternet2(use=FALSE)
  
  #---------------------------------------------------------------------------------------------------------------#
  #4. process temporal constraints info.
  #---------------------------------------------------------------------------------------------------------------#
  
  #estimate starting doy and extract year info.
  tmp = strsplit(start, "-")
  sYear = as.numeric(tmp[[1]][1])
  month = as.numeric(tmp[[1]][2])
  day = as.numeric(tmp[[1]][3])
  sDoy = floor(275. * month / 9.) - (floor((month + 9.) / 12.) * 
                                       (1. + floor((sYear - 4. * floor(sYear / 4.) + 2.) / 3.))) + day - 30.
  
  rm(tmp, day)
  
  #estimate ending doy and extract year info.
  tmp = strsplit(end, "-")
  eYear = as.numeric(tmp[[1]][1])
  month = as.numeric(tmp[[1]][2])
  day = as.numeric(tmp[[1]][3])
  eDoy = floor(275. * month / 9.) - (floor((month + 9.) / 12.) * 
                                       (1. + floor((eYear - 4. * floor(eYear / 4.) + 2.) / 3.))) + day - 30.
  
  rm(tmp, day)
  
  #---------------------------------------------------------------------------------------------------------------#
  #5. determine yearly temporal constraints (start-end doy to download)
  #---------------------------------------------------------------------------------------------------------------#
  
  #number of year
  nYears = (eYear - sYear) + 1
  
  #extract temporal boundaries per year
  tb = vector("list",nYears)
  if(sYear == eYear) {tb[[1]] = c(sDoy,eDoy)}
  if(sYear != eYear) {
    for(y in 1:nYears){
      if(y != nYears) {
        if((sYear+(y-1) %% 4) > 1) {nDays = 366} else {nDays = 365}   #number of days in the year
        if(y == 1) {tb[[y]] = c(sDoy,nDays)}
        if(y > 1) {tb[[y]] = c(0,nDays)}
      }
      if(y == nYears) {tb[[y]] = c(0,as.numeric(eDoy))}
    }
  }
  
  #---------------------------------------------------------------------------------------------------------------#
  #5. loop trough each target product
  #---------------------------------------------------------------------------------------------------------------#
  
  #evaluate each target dataset
  for(p in 1:length(ds)) {
    
    #loop through each year
    for(y in 1:nYears) {
      
      #determine target folder
      baseURL = paste(server, ds[p], "/", as.character(sYear+(y-1)), "/", sep="")
      
      #extract doy directory list
      dirLs = strsplit(getURL(baseURL, ftp.use.epsv = FALSE, dirlistonly = TRUE), "\r\n", fixed=TRUE)
      doyLs = as.numeric(unlist(dirLs))
      loc = which(doyLs >= tb[[y]][1] & doyLs <= tb[[y]][2])
      
      #initiate data download
      for(l in 1:length(loc)) {
        
        doyURL = paste(baseURL, dirLs[[1]][loc[l]], '/', sep="")
        ls = strsplit(getURL(doyURL,verbose=FALSE,ftp.use.epsv=FALSE,dirlistonly = TRUE), "\r\n", fixed=TRUE)
        tFile = ls[[1]][grep(paste("h", h, "v", v, sep=""), ls[[1]])]
        #download.file(paste(doyURL, tFile, sep=""), paste(odir, tFile, sep=""), quiet=TRUE)
        download.file(paste(doyURL, tFile, sep=""), paste(odir, tFile, sep=""), method="libcurl", quiet=TRUE)
        
        rm(doyURL, ls, tFile) #remove temporary variables
        
      }
      
      rm(baseURL, dirLs, doyLs, loc) #remove temporary variables
      
    }
  }
  
  #---------------------------------------------------------------------------------------------------------------#
  
}
